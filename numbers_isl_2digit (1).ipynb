{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in /opt/anaconda3/lib/python3.8/site-packages (0.8.9.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.8/site-packages (from mediapipe) (1.20.1)\n",
      "Requirement already satisfied: absl-py in /opt/anaconda3/lib/python3.8/site-packages (from mediapipe) (1.0.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /opt/anaconda3/lib/python3.8/site-packages (from mediapipe) (20.3.0)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.8/site-packages (from mediapipe) (3.3.4)\n",
      "Requirement already satisfied: opencv-contrib-python in /opt/anaconda3/lib/python3.8/site-packages (from mediapipe) (4.5.5.64)\n",
      "Requirement already satisfied: protobuf>=3.11.4 in /opt/anaconda3/lib/python3.8/site-packages (from mediapipe) (3.19.4)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.8/site-packages (from absl-py->mediapipe) (1.15.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib->mediapipe) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib->mediapipe) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib->mediapipe) (2.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib->mediapipe) (8.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib->mediapipe) (0.10.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chime\n",
      "  Downloading chime-0.6.0-py3-none-any.whl (2.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.3 MB 2.3 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: chime\n",
      "Successfully installed chime-0.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install chime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, None, 36) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 36), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 36).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 36) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 36), dtype=tf.float32, name='dense_28_input'), name='dense_28_input', description=\"created by layer 'dense_28_input'\"), but it was called on an input with incompatible shape (None, 36).\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "#from collect import get_connections_list, get_distance\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import operator\n",
    "import chime\n",
    "chime.theme('zelda')\n",
    "\n",
    "def get_connections_list():\n",
    "    # All landmark names and values: https://google.github.io/mediapipe/images/mobile/hand_landmarks.png\n",
    "    return {\n",
    "        \"WRIST_TO_THUMB_MCP\": (0, 2),\n",
    "        \"WRIST_TO_THUMB_IP\": (0, 3),\n",
    "        \"WRIST_TO_THUMB_TIP\": (0, 4),\n",
    "        \"WRIST_TO_INDEX_FINGER_PIP\": (0, 6),\n",
    "        \"WRIST_TO_INDEX_FINGER_DIP\": (0, 7),\n",
    "        \"WRIST_TO_INDEX_FINGER_TIP\": (0, 8),\n",
    "        \"WRIST_TO_MIDDLE_FINGER_PIP\": (0, 10),\n",
    "        \"WRIST_TO_MIDDLE_FINGER_DIP\": (0, 11),\n",
    "        \"WRIST_TO_MIDDLE_FINGER_TIP\": (0, 12),\n",
    "        \"WRIST_TO_RING_FINGER_PIP\": (0, 14),\n",
    "        \"WRIST_TO_RING_FINGER_DIP\": (0, 15),\n",
    "        \"WRIST_TO_RING_FINGER_TIP\": (0, 16),\n",
    "        \"WRIST_TO_PINKY_PIP\": (0, 18),\n",
    "        \"WRIST_TO_PINKY_DIP\": (0, 19),\n",
    "        \"WRIST_TO_PINKY_TIP\": (0, 20),\n",
    "        \"THUMB_MCP_TO_THUMB_TIP\": (2, 4),\n",
    "        \"INDEX_FINGER_MCP_TO_INDEX_FINGER_TIP\": (5, 8),\n",
    "        \"MIDDLE_FINGER_MCP_TO_MIDDLE_FINGER_TIP\": (9, 12),\n",
    "        \"RING_FINGER_MCP_TO_RING_FINGER_TIP\": (13, 16),\n",
    "        \"PINKY_MCP_TO_PINKY_TIP\": (17, 20),\n",
    "        \"THUMB_TIP_TO_INDEX_FINGER_MCP\": (4, 5),\n",
    "        \"THUMB_TIP_TO_INDEX_FINGER_PIP\": (4, 6),\n",
    "        \"THUMB_TIP_TO_INDEX_FINGER_DIP\": (4, 7),\n",
    "        \"THUMB_TIP_TO_INDEX_FINGER_TIP\": (4, 8),\n",
    "        \"THUMB_TIP_TO_MIDDLE_FINGER_MCP\": (4, 9),\n",
    "        \"THUMB_TIP_TO_MIDDLE_FINGER_PIP\": (4, 10),\n",
    "        \"THUMB_TIP_TO_MIDDLE_FINGER_DIP\": (4, 11),\n",
    "        \"THUMB_TIP_TO_MIDDLE_FINGER_TIP\": (4, 12),\n",
    "        \"THUMB_TIP_TO_RING_FINGER_MCP\": (4, 13),\n",
    "        \"THUMB_TIP_TO_RING_FINGER_PIP\": (4, 14),\n",
    "        \"THUMB_TIP_TO_RING_FINGER_DIP\": (4, 15),\n",
    "        \"THUMB_TIP_TO_RING_FINGER_TIP\": (4, 16),\n",
    "        \"THUMB_TIP_TO_PINKY_MCP\": (4, 17),\n",
    "        \"THUMB_TIP_TO_PINKY_PIP\": (4, 18),\n",
    "        \"THUMB_TIP_TO_PINKY_DIP\": (4, 19),\n",
    "        \"THUMB_TIP_TO_PINKY_TIP\": (4, 20)\n",
    "    }\n",
    "\n",
    "def get_distance(first, second):\n",
    "    # Calculate distance from two coordinates\n",
    "    return np.sqrt(\n",
    "        (first.x - second.x) ** 2 \n",
    "        + (first.y - second.y) ** 2 \n",
    "        + (first.z - second.z) ** 2\n",
    "    )\n",
    "def pred(landmarks):\n",
    "\n",
    "# def pred(landmarks,model):\n",
    "    connections_dict = get_connections_list()\n",
    "    coordinates = landmarks.landmark\n",
    "    data = []\n",
    "    for _, values in connections_dict.items():\n",
    "            data.append(get_distance(coordinates[values[0]], coordinates[values[1]])) \n",
    "    data = np.array([data])\n",
    "    return data\n",
    "\n",
    "def get_sign_list():\n",
    "    # Function to get all the values in SIGN column\n",
    "    df = pd.read_csv('/Users/kritika/Desktop/HGR/merged-csv-files.csv')\n",
    "    return df['Sign'].unique()\n",
    "\n",
    "def real_time_prediction():\n",
    "    #model = load_model('model_a.h5')\n",
    "    single_model = load_model('/Users/kritika/Desktop/HGR/final_single_hand1.h5')\n",
    "    double_model = load_model('/Users/kritika/Desktop/HGR/final_double_hand_alphabetv2.h5')\n",
    "    space_model = load_model('/Users/kritika/Desktop/HGR/space.h5')\n",
    "    sign_list = get_sign_list()\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    mp_hands = mp.solutions.hands\n",
    "    connections_dict = get_connections_list()\n",
    "    single_hand_list = ['0','1','2','3','4','5','6','7','8','9','C','I','L','O','U','V']\n",
    "    double_hand_list = ['A', 'B', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'M', 'N', 'P', 'Q',\n",
    "       'R', 'S', 'T', 'W', 'X', 'Y', 'Z']\n",
    "    flag_check = 0\n",
    "    # Initialize webcam\n",
    "    # Default is zero, try changing value if it doesn't work\n",
    "    fr = 1\n",
    "    hands=mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    s = \"\"\n",
    "    flow = ''\n",
    "    while cap.isOpened():\n",
    "        _, frame = cap.read()\n",
    "        frame.flags.writeable = True\n",
    "        results = hands.process(frame)\n",
    "        if  results.multi_hand_landmarks:\n",
    "                flag = 1  \n",
    "                for res in results.multi_hand_landmarks:\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                            frame, res, mp_hands.HAND_CONNECTIONS)\n",
    "                flow = results.multi_handedness[0].classification[0].label\n",
    "                if(len(results.multi_hand_landmarks)==2):      \n",
    "                    if(flag_check == 0):\n",
    "                        fr = 1\n",
    "                        flag_check = 1\n",
    "                    if(flow=='Left'):\n",
    "                        coordinates = results.multi_hand_landmarks[0].landmark\n",
    "                        coordinates1 = results.multi_hand_landmarks[1].landmark\n",
    "                    else:\n",
    "                        coordinates = results.multi_hand_landmarks[1].landmark\n",
    "                        coordinates1 = results.multi_hand_landmarks[0].landmark\n",
    "                    row0 =[]\n",
    "                    row1 = []\n",
    "                    row2 = []\n",
    "                    for _,values in connections_dict.items():\n",
    "                        row0.append(get_distance(coordinates[values[0]], coordinates[values[1]]))\n",
    "                        row1.append(get_distance(coordinates[values[0]], coordinates[values[1]]))\n",
    "                        row0.append(get_distance(coordinates1[values[0]], coordinates1[values[1]]))\n",
    "                        row2.append(get_distance(coordinates1[values[0]], coordinates1[values[1]]))\n",
    "                    check_prev_ans = single_hand_list[single_model.predict(np.expand_dims(row1,axis = 0)).argmax()]\n",
    "                    check_prev_ans1 = single_hand_list[single_model.predict(np.expand_dims(row2,axis = 0)).argmax()]\n",
    "                    ans_check = double_model.predict(np.expand_dims(row0,axis = 0))\n",
    "#                     print(row1,row0,double_hand_list[ans_check.argmax()])\n",
    "                    check = ans_check.max()\n",
    "                    if(check > 0.9):\n",
    "                        ans = double_hand_list[ans_check.argmax()]\n",
    "                        if( fr%15 == 0 and flag_check==1):\n",
    "                            if(len(s) == 0):\n",
    "                                s += ans\n",
    "                                flag_check = 0\n",
    "                            elif(s[-1]!=ans and (s[-1] == check_prev_ans or s[-1] == check_prev_ans1)):\n",
    "                                s = s[:-1] + ans\n",
    "                                flag_check = 0\n",
    "                            elif(s[-1]!=ans):\n",
    "                                s += ans\n",
    "                                flag_check = 0\n",
    "                            fr = 0\n",
    "                    fr +=1      \n",
    "                else:\n",
    "                    if(flag_check == 0):\n",
    "                        fr = 1\n",
    "                        flag_check = 1\n",
    "                    coordinates = results.multi_hand_landmarks[0].landmark\n",
    "                    row0=[]\n",
    "                    for _,values in connections_dict.items():\n",
    "                        row0.append(get_distance(coordinates[values[0]], coordinates[values[1]])) \n",
    "                    check_ans = space_model.predict(np.expand_dims(row0,axis = 0))\n",
    "                    ans = single_hand_list[single_model.predict(np.expand_dims(row0,axis = 0)).argmax()]\n",
    "                    if( fr%15 == 0 and flag_check==1):\n",
    "                        if(check_ans/0.5>0.85):\n",
    "                            s += \" \"\n",
    "                            chime.info()\n",
    "                            flag_check = 0\n",
    "                        elif(len(s) == 0):\n",
    "                            s += ans\n",
    "                            flag_check = 0\n",
    "                        elif(s[-1]!=ans):\n",
    "                            s += ans\n",
    "                            flag_check = 0\n",
    "                        fr = 0\n",
    "                    fr +=1      \n",
    "                  \n",
    "        frame =cv2.flip(frame, 1) \n",
    "        cv2.putText(frame, s, (20, 90), cv2.FONT_HERSHEY_SIMPLEX, 3, (255, 0, 0), 2)                    \n",
    "        cv2.imshow('Sign Language Detection',frame)\n",
    "        flag = 0\n",
    "        if cv2.waitKey(20) & 0xFF == ord('c'):\n",
    "            s = \"\"\n",
    "        if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "        \n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    real_time_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
